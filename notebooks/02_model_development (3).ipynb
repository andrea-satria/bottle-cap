{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Bottle Cap Color Detection for YOLOv8 (Model Development)"
      ],
      "metadata": {
        "id": "WcvT4z3HTzpX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b0aea4c"
      },
      "source": [
        "## Project Introduction\n",
        "\n",
        "This project focuses on developing a robust object detection model for **bottle cap color detection using YOLOv8**. The primary goal is to accurately identify and classify bottle caps based on their colors, such as light blue, dark blue, and other colors.\n",
        "\n",
        "### Purpose and Importance\n",
        "\n",
        "Accurate bottle cap color detection is crucial for various industrial applications, including:\n",
        "\n",
        "*   **Quality Control:** Ensuring that bottles are sealed with the correct colored caps, preventing packaging errors.\n",
        "*   **Automated Sorting:** Facilitating the automatic sorting of products based on cap color, streamlining manufacturing processes.\n",
        "*   **Inventory Management:** Aiding in the automated tracking and management of products by their cap specifications.\n",
        "\n",
        "### Technology\n",
        "\n",
        "We leverage **YOLOv8 (You Only Look Once version 8)**, a state-of-the-art, real-time object detection algorithm. YOLOv8 is chosen for its superior speed and accuracy, making it an ideal candidate for deployment in environments requiring quick processing, such as on edge devices like the Raspberry Pi 5. The project includes training a custom YOLOv8 model, optimizing it for performance, and evaluating its efficiency in detecting bottle cap colors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c315440c"
      },
      "source": [
        "### Environment Setup\n",
        "\n",
        "To ensure a smooth model development and training process, it's crucial to set up the environment correctly. This involves verifying GPU availability and installing all necessary libraries.\n",
        "\n",
        "#### 1. Verify GPU Availability\n",
        "\n",
        "GPU acceleration significantly speeds up model training. Before proceeding, confirm that a GPU is available and properly configured:\n",
        "\n",
        "- **Check CUDA availability**: Use `torch.cuda.is_available()` to determine if PyTorch can detect a CUDA-compatible GPU.\n",
        "- **Identify GPU**: If a GPU is available, you can get its name and memory using `torch.cuda.get_device_name(0)` and `torch.cuda.get_device_properties(0).total_memory / 1e9`.\n",
        "- **Action**: If no GPU is found or it's not detected, consider changing the Colab runtime type to include a GPU (e.g., T4 GPU).\n",
        "\n",
        "#### 2. Install Required Libraries\n",
        "\n",
        "Several Python libraries are essential for YOLOv8 model development, training, and deployment. These can be installed using `pip`:\n",
        "\n",
        "- `ultralytics`: The core library for YOLOv8 models.\n",
        "- `wandb`: For experiment tracking and visualization (Weights & Biases).\n",
        "- `onnx`: For Open Neural Network Exchange format handling, crucial for model export.\n",
        "- `onnxruntime`: The ONNX runtime for efficient model inference.\n",
        "- `onnxruntime-tools`: Additional tools for ONNX, including quantization.\n",
        "\n",
        "These steps ensure that your environment is fully prepared for the subsequent stages of model development, training, and optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu7ZROtpKGlO",
        "outputId": "5001fc85-90ac-4e31-9dd9-4511ed74a17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PyTorch: 2.9.0+cu126\n",
            "CUDA Available: True\n",
            "GPU: Tesla T4\n",
            "Memory: 15.8 GB\n",
            "\n",
            "âœ… GPU READY!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\nâœ… GPU READY!\")\n",
        "else:\n",
        "    print(\"\\n NO GPU!\")\n",
        "    print(\"Go to: Runtime â†’ Change runtime type â†’ T4 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHNmNWU9K7sT",
        "outputId": "f5f6b40a-489b-45b7-b9f8-84104ada9cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics wandb onnx onnxruntime onnxruntime-tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "648231bd"
      },
      "source": [
        "### Dataset Preparation\n",
        "\n",
        "To begin, the YOLOv8 dataset, provided as a `yolo_dataset.zip` file, needs to be unzipped. This action extracts all necessary image and label files into a structured directory.\n",
        "\n",
        "Once unzipped, the integrity and structure of the dataset are crucial for successful model training. The first step in verification is to locate the `data.yaml` file, which contains essential metadata about the dataset, including class names and paths to the training, validation, and testing sets.\n",
        "\n",
        "Following this, the number of images in each of the `train`, `val`, and `test` directories is counted to ensure a complete and balanced dataset split. This verification step is vital to confirm that the dataset is properly organized and ready for the YOLOv8 model training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3E6WqlfL0f9",
        "outputId": "04d8d8cd-792b-421d-8dcd-bbe313625276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/yolo_dataset.zip\n",
            "   creating: yolo_dataset/\n",
            "   creating: yolo_dataset/test/\n",
            "   creating: yolo_dataset/train/\n",
            "   creating: yolo_dataset/val/\n",
            "  inflating: yolo_dataset/data.yaml  \n",
            "   creating: yolo_dataset/train/images/\n",
            "   creating: yolo_dataset/train/labels/\n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_13_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_13_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_13_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_2_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_2_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_0_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_2_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_1_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_2_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_13_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_12_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_13_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_5_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_9_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_15_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_2_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_2_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_10_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_4_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_14_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_8_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_7_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_6_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_11_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_13_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/train/labels/aug_3_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_2_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_13_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_13_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_13_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_13_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_2_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_2_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_2_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_2_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_2_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_0_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_1_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_9_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_15_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_11_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_6_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_13_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_13_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_14_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_7_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_4_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_8_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_3_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_5_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_12_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/train/images/aug_10_raw-250110_dc_s001_b2_1.jpg  \n",
            "   creating: yolo_dataset/test/images/\n",
            "   creating: yolo_dataset/test/labels/\n",
            "  inflating: yolo_dataset/test/labels/aug_10_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_13_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_0_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_13_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_11_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_7_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_4_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_14_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_1_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_9_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_6_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_2_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_12_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_0_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_14_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_15_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_2_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_7_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_3_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/test/labels/aug_3_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/test/images/aug_9_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_2_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_13_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_2_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_0_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_11_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_7_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_14_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_12_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_15_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_0_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_10_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_14_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_6_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_1_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_13_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_3_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_7_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_3_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/test/images/aug_4_raw-250110_dc_s001_b4_3.jpg  \n",
            "   creating: yolo_dataset/val/images/\n",
            "   creating: yolo_dataset/val/labels/\n",
            "  inflating: yolo_dataset/val/labels/aug_3_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_7_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_13_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_0_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_10_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_6_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_8_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_1_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_6_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_6_raw-250110_dc_s001_b3_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_0_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_11_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_1_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_14_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_2_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_15_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_5_raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_2_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_8_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_11_raw-250110_dc_s001_b4_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_9_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_9_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_12_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_9_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_3_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_3_raw-250110_dc_s001_b4_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_5_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_15_raw-250110_dc_s001_b5_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_9_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_8_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_5_raw-250110_dc_s001_b5_5.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_5_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_2_raw-250110_dc_s001_b4_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_11_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/val/labels/raw-250110_dc_s001_b5_3.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_2_raw-250110_dc_s001_b2_1.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_13_raw-250110_dc_s001_b3_2.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_13_raw-250110_dc_s001_b2_15.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_13_raw-250110_dc_s001_b3_4.txt  \n",
            "  inflating: yolo_dataset/val/labels/aug_0_raw-250110_dc_s001_b2_3.txt  \n",
            "  inflating: yolo_dataset/val/images/aug_2_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_9_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b3_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_9_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_1_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_0_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_15_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_12_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_8_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_10_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b3_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_0_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_1_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_2_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_11_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_15_raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_0_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_7_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_14_raw-250110_dc_s001_b4_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_8_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_8_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/raw-250110_dc_s001_b5_2.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_5_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_11_raw-250110_dc_s001_b4_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_9_raw-250110_dc_s001_b5_5.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_5_raw-250110_dc_s001_b4_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_2_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_5_raw-250110_dc_s001_b5_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_9_raw-250110_dc_s001_b2_3.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_2_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_11_raw-250110_dc_s001_b3_4.jpg  \n",
            "  inflating: yolo_dataset/val/images/aug_5_raw-250110_dc_s001_b5_5.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/yolo_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Wv6NyYLArv",
        "outputId": "b67f3168-7096-4d7a-b90b-576d8eafde5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "data.yaml found\n",
            "\n",
            "ðŸ“Š Dataset Split:\n",
            "   Train: 142 images\n",
            "   Val: 41 images\n",
            "   Test: 21 images\n",
            "\n",
            "ðŸ“„ data.yaml content:\n",
            "path: /content/yolo_dataset\n",
            "train: train/images\n",
            "val: val/images\n",
            "test: test/images\n",
            "nc: 3\n",
            "names:\n",
            "- light_blue\n",
            "- dark_blue\n",
            "- others\n",
            "\n",
            "DATASET READY FOR TRAINING!\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import wandb\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "data_yaml = Path('/content/yolo_dataset/data.yaml')\n",
        "\n",
        "if not data_yaml.exists():\n",
        "    print(\"âŒ Dataset not found!\")\n",
        "    print(\"\\nðŸ’¡ Run Notebook 1 first to prepare dataset!\")\n",
        "    print(\"   Or make sure /content/yolo_dataset exists\")\n",
        "else:\n",
        "    print(\"data.yaml found\")\n",
        "\n",
        "    train_imgs = len(list(Path('/content/yolo_dataset/train/images').glob('*')))\n",
        "    val_imgs = len(list(Path('/content/yolo_dataset/val/images').glob('*')))\n",
        "    test_imgs = len(list(Path('/content/yolo_dataset/test/images').glob('*')))\n",
        "\n",
        "    print(f\"\\nðŸ“Š Dataset Split:\")\n",
        "    print(f\"   Train: {train_imgs} images\")\n",
        "    print(f\"   Val: {val_imgs} images\")\n",
        "    print(f\"   Test: {test_imgs} images\")\n",
        "\n",
        "    print(f\"\\nðŸ“„ data.yaml content:\")\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        print(f.read())\n",
        "\n",
        "    if train_imgs > 0 and val_imgs > 0:\n",
        "        print(\"DATASET READY FOR TRAINING!\")\n",
        "    else:\n",
        "        print(\"Dataset incomplete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97759687"
      },
      "source": [
        "### Weights & Biases Integration\n",
        "\n",
        "Weights & Biases (WandB) will be an integral tool for experiment tracking, visualization, and logging throughout our YOLOv8 model training process. It provides a robust platform to manage machine learning experiments.\n",
        "\n",
        "To connect to the WandB platform, we will use the `wandb.login()` function. This authenticates our session, allowing us to interact with the WandB service.\n",
        "\n",
        "The benefits of using WandB are numerous:\n",
        "*   **Tracking Metrics**: Automatically log training and validation metrics (e.g., loss, precision, recall, mAP) over epochs.\n",
        "*   **Visualizing Predictions**: Log sample predictions, allowing us to visually inspect how the model performs on validation images at different stages of training.\n",
        "*   **Managing Runs**: Easily compare different training runs, including their configurations, hyperparameters, and results.\n",
        "*   **Configuration Management**: Store all hyperparameters and configurations used for a specific run, ensuring reproducibility.\n",
        "*   **Artifacts**: Save model checkpoints and other relevant files directly to WandB, creating a centralized repository for our project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GgBoJCkMEkC",
        "outputId": "1630dfb4-9279-4361-c95b-a0a2e15a6784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreanagari\u001b[0m (\u001b[33mandreanagari-unemployed\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WandB login successful!\n"
          ]
        }
      ],
      "source": [
        "wandb.login()\n",
        "\n",
        "print(\"WandB login successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "i2jQlJTZO1zh",
        "outputId": "96dc0991-1ecf-47e8-e904-9ff2ad6c9fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ðŸ”¥ STARTING TRAINING (ENHANCED WANDB LOGGING)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251126_060613-khtuz98m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m' target=\"_blank\">yolov8n-final2</a></strong> to <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Dashboard Link: https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 122.6MB/s 0.1s\n",
            "\n",
            "ðŸ”¥ Starting training...\n",
            "Ultralytics 8.3.232 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 23.5MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 98.5MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1303.9Â±582.9 MB/s, size: 218.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/train/labels... 142 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 142/142 2.0Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 879.7Â±557.3 MB/s, size: 240.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/val/labels... 41 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 845.3it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/val/labels.cache\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/150     0.334G      1.378      3.327     0.9319         61        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 4.7it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.3it/s 1.3s\n",
            "                   all         41        261    0.00333      0.295      0.128     0.0337\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 (no detections), 36.5ms\n",
            "Speed: 0.9ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 (no detections), 5.8ms\n",
            "Speed: 1.0ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 (no detections), 5.7ms\n",
            "Speed: 1.0ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/150     0.365G      1.201      2.039     0.8934         47        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.9it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.3it/s 0.4s\n",
            "                   all         41        261     0.0842      0.867      0.351      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/150     0.379G      1.216      1.639     0.8868         82        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.9it/s 0.4s\n",
            "                   all         41        261      0.191      0.965      0.479      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/150       0.4G      1.117      1.472     0.8758         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.5it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.2it/s 0.4s\n",
            "                   all         41        261      0.603      0.823      0.701      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/150     0.438G      1.102      1.322     0.8816         60        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.4it/s 0.4s\n",
            "                   all         41        261      0.638      0.821      0.703       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/150     0.455G      1.057      1.288     0.8751         62        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.5it/s 0.3s\n",
            "                   all         41        261      0.717      0.899      0.781      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/150     0.471G      1.095      1.177     0.8851         39        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.8it/s 0.3s\n",
            "                   all         41        261      0.806      0.869      0.838      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/150     0.488G      1.008      1.167     0.8706         56        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.1it/s 0.3s\n",
            "                   all         41        261      0.813      0.888      0.905      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/150       0.5G     0.9818      1.033     0.8578         85        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.5it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.0it/s 0.5s\n",
            "                   all         41        261      0.884      0.878      0.957      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/150     0.521G      1.002      1.016       0.87         52        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.2it/s 0.3s\n",
            "                   all         41        261      0.835      0.939       0.98      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/150     0.539G      1.044     0.9849     0.8624         92        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.9it/s 0.3s\n",
            "                   all         41        261      0.921      0.889      0.989      0.705\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 8 otherss, 7.7ms\n",
            "Speed: 1.0ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 5.9ms\n",
            "Speed: 1.1ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 2 otherss, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/150     0.564G      1.173     0.9571     0.8822         87        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.1it/s 0.3s\n",
            "                   all         41        261      0.935      0.938      0.988      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/150     0.584G      1.038     0.8749     0.8638         87        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.6it/s 0.4s\n",
            "                   all         41        261      0.971       0.93      0.986      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/150       0.6G      1.072     0.8685     0.8672         74        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.2it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.1it/s 0.4s\n",
            "                   all         41        261      0.959      0.933      0.986      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/150     0.617G     0.9862     0.8491     0.8634         58        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.2it/s 0.3s\n",
            "                   all         41        261       0.99      0.959      0.992      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/150     0.635G      1.005      0.857     0.8705         83        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.3it/s 0.3s\n",
            "                   all         41        261      0.983      0.974      0.993      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/150      0.65G      0.944     0.8158     0.8635         47        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.2it/s 0.3s\n",
            "                   all         41        261      0.982      0.946      0.992      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/150     0.668G     0.9474     0.7746     0.8448         73        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.4it/s 0.3s\n",
            "                   all         41        261       0.98      0.987      0.995      0.732\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/150     0.686G     0.9386     0.7743     0.8594         58        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.5it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 5.9it/s 0.5s\n",
            "                   all         41        261      0.975      0.995      0.994      0.757\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/150     0.703G     0.8721     0.7582     0.8415         60        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.2it/s 0.3s\n",
            "                   all         41        261      0.973      0.987      0.994      0.754\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/150     0.719G     0.9036     0.7385     0.8533         68        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.9it/s 0.3s\n",
            "                   all         41        261      0.975      0.979      0.992      0.757\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 8 otherss, 5.8ms\n",
            "Speed: 0.8ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 16.8ms\n",
            "Speed: 3.4ms preprocess, 16.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 3 otherss, 5.8ms\n",
            "Speed: 0.9ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/150     0.746G      0.886     0.7006     0.8386        106        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.4it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.7it/s 0.3s\n",
            "                   all         41        261      0.966       0.98      0.991      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/150     0.764G     0.9218     0.6933      0.852         77        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.7it/s 0.4s\n",
            "                   all         41        261      0.963      0.987      0.993      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/150     0.781G     0.8945     0.6905     0.8477         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.8it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.0it/s 0.3s\n",
            "                   all         41        261      0.952      0.983      0.993      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/150     0.797G     0.8602     0.6919     0.8465         53        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.5it/s 0.4s\n",
            "                   all         41        261      0.972       0.99      0.994       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/150     0.811G     0.9017     0.7084     0.8569         34        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.5it/s 0.3s\n",
            "                   all         41        261      0.991       0.98      0.994      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/150     0.832G     0.8728     0.6859     0.8459         58        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.5it/s 0.3s\n",
            "                   all         41        261       0.99       0.98      0.994       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/150     0.848G      0.826     0.6368     0.8356         83        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.9it/s 0.3s\n",
            "                   all         41        261      0.989      0.978      0.994      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/150     0.865G     0.8127     0.6256     0.8424         57        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.1it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.2it/s 0.4s\n",
            "                   all         41        261       0.98      0.962      0.993      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/150     0.883G     0.8461     0.6452     0.8401         77        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.7it/s 0.3s\n",
            "                   all         41        261      0.949      0.952      0.992      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/150       0.9G      0.827     0.6594     0.8416         54        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.9it/s 0.3s\n",
            "                   all         41        261       0.97      0.972      0.994      0.824\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 7.8ms\n",
            "Speed: 1.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 3 otherss, 7.7ms\n",
            "Speed: 1.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/150     0.928G     0.8203     0.6101     0.8358         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.3it/s 0.3s\n",
            "                   all         41        261      0.968      0.998      0.994      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/150     0.945G     0.8022     0.6068     0.8386         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.1it/s 0.4s\n",
            "                   all         41        261      0.978      0.996      0.994      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/150     0.961G     0.8108     0.6149     0.8299         40        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.4it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.7it/s 0.3s\n",
            "                   all         41        261      0.989      0.976      0.994      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/150     0.979G     0.7258     0.5615     0.8217         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.3it/s 0.3s\n",
            "                   all         41        261      0.991      0.982      0.995      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/150     0.994G     0.7972     0.5911     0.8328         38        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.6it/s 0.3s\n",
            "                   all         41        261      0.995      0.986      0.995      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/150      1.01G     0.7779     0.5938     0.8312         79        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.1it/s 0.3s\n",
            "                   all         41        261      0.999      0.987      0.995      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/150      1.03G     0.7748     0.5668     0.8306         33        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.1it/s 0.3s\n",
            "                   all         41        261      0.984      0.987      0.995      0.816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/150      1.05G     0.7475     0.5519     0.8292         62        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.1it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.4it/s 0.5s\n",
            "                   all         41        261      0.967      0.996      0.995      0.783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/150      1.06G     0.8134     0.5836     0.8325         92        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.8it/s 0.3s\n",
            "                   all         41        261       0.97      0.991      0.995      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/150      1.08G     0.7422     0.5415     0.8304         61        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.2it/s 0.3s\n",
            "                   all         41        261      0.983      0.985      0.995       0.81\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 3 otherss, 6.0ms\n",
            "Speed: 1.0ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/150      1.11G     0.7858     0.5838     0.8345         54        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.4it/s 0.3s\n",
            "                   all         41        261      0.983      0.989      0.995      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/150      1.12G     0.7792     0.5727     0.8402         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.985      0.983      0.994      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/150      1.14G     0.7623     0.5453     0.8288         62        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.4it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.0it/s 0.4s\n",
            "                   all         41        261      0.986      0.989      0.994      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/150      1.16G     0.7897     0.5677     0.8336         56        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.1it/s 0.3s\n",
            "                   all         41        261      0.987      0.994      0.995      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/150      1.18G      0.767     0.5501     0.8311         36        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.4it/s 0.3s\n",
            "                   all         41        261      0.996      0.986      0.995      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/150      1.19G     0.7465      0.552     0.8247         55        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         41        261      0.991      0.996      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/150      1.21G     0.8005     0.5382     0.8265         76        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.998      0.986      0.995      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/150      1.23G     0.7764     0.5456     0.8314         72        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.8it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.6it/s 0.5s\n",
            "                   all         41        261      0.995      0.992      0.995      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/150      1.24G      0.749     0.5359     0.8266         51        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.9it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.3it/s 0.3s\n",
            "                   all         41        261      0.995      0.991      0.995      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/150      1.26G     0.7526     0.5375     0.8256         78        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         41        261      0.994      0.992      0.995      0.812\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 8.3ms\n",
            "Speed: 1.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 3 otherss, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/150      1.29G     0.8089     0.5649     0.8329         59        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5it/s 0.3s\n",
            "                   all         41        261      0.997      0.986      0.995      0.819\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/150       1.3G     0.7366     0.5358     0.8181         54        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         41        261      0.999      0.985      0.995      0.829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/150      1.32G      0.735     0.5344     0.8174         51        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.3it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.1it/s 0.5s\n",
            "                   all         41        261      0.999      0.991      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/150      1.34G     0.7492     0.5185     0.8305         59        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.9it/s 0.3s\n",
            "                   all         41        261      0.999      0.993      0.995      0.828\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/150      1.36G     0.7188     0.4897     0.8119         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.7it/s 0.3s\n",
            "                   all         41        261          1      0.994      0.995      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/150      1.37G      0.724     0.5123     0.8296         82        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         41        261          1      0.995      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/150      1.39G     0.7084     0.5032     0.8238         82        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.0it/s 0.3s\n",
            "                   all         41        261          1      0.995      0.995      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/150      1.41G     0.7578     0.5338     0.8213         59        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.2it/s 0.5s\n",
            "                   all         41        261      0.994      0.994      0.995      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/150      1.42G      0.729     0.5012     0.8251         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.7it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.1it/s 0.3s\n",
            "                   all         41        261      0.992       0.99      0.995      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/150      1.44G     0.7182     0.5062     0.8291         33        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         41        261      0.994       0.99      0.995      0.845\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 5.8ms\n",
            "Speed: 0.8ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 6.0ms\n",
            "Speed: 1.0ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/150      1.47G     0.7061     0.4874     0.8191         45        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.8it/s 0.3s\n",
            "                   all         41        261      0.999      0.993      0.995      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/150      1.49G     0.6859     0.5071     0.8214         61        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         41        261      0.999      0.993      0.995      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/150       1.5G     0.6996     0.4767     0.8157         69        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.8it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.4it/s 0.5s\n",
            "                   all         41        261      0.998      0.996      0.995      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/150      1.52G     0.7049     0.5091     0.8269         36        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.0it/s 0.3s\n",
            "                   all         41        261      0.992      0.993      0.995      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/150      1.54G     0.7002     0.4729     0.8193         46        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.0it/s 0.3s\n",
            "                   all         41        261       0.98      0.982      0.995      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/150      1.55G     0.6954     0.4767     0.8234         33        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261       0.99      0.981      0.995      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/150      1.57G      0.678     0.4711     0.8146         74        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261      0.996      0.989      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/150      1.59G     0.6786     0.4664     0.8107         78        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.3it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 5.8it/s 0.5s\n",
            "                   all         41        261      0.995      0.992      0.995      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/150      1.61G     0.6964     0.4794     0.8218         56        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.1it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         41        261       0.99      0.995      0.995      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/150      1.62G     0.7128     0.4717     0.8236         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261      0.991      0.989      0.995      0.852\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 8.1ms\n",
            "Speed: 1.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.3ms\n",
            "Speed: 1.1ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/150      1.65G     0.7162     0.4929     0.8261         56        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.989      0.994      0.995      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/150      1.67G     0.6718     0.4711     0.8217         39        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261      0.986      0.994      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/150      1.68G     0.6741     0.4481     0.8192         52        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.8it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.2it/s 0.5s\n",
            "                   all         41        261       0.99      0.987      0.995      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/150       1.7G     0.6468     0.4622     0.8205         43        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.0it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         41        261      0.993      0.993      0.995      0.862\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/150      1.72G     0.6536     0.4503     0.8174         61        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.995      0.998      0.995      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/150      1.73G     0.6787     0.4576     0.8182         45        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261      0.996      0.998      0.995      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/150      1.75G     0.6641     0.4478     0.8215         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261      0.997      0.998      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/150      1.77G     0.6611      0.441     0.8095         78        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.8it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.0it/s 0.5s\n",
            "                   all         41        261      0.999      0.995      0.995       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/150      1.79G     0.6848     0.4543     0.8179         91        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         41        261          1      0.992      0.995      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/150       1.8G     0.6927     0.4504     0.8225         56        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.9it/s 0.3s\n",
            "                   all         41        261      0.995      0.987      0.995      0.849\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 5.7ms\n",
            "Speed: 0.9ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 7.8ms\n",
            "Speed: 1.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/150      1.83G     0.6694     0.4412     0.8174         60        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.3it/s 0.3s\n",
            "                   all         41        261      0.997      0.987      0.995      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/150      1.84G     0.6786     0.4481     0.8139         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.999      0.986      0.995       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/150      1.86G     0.6717     0.4649     0.8163         70        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.0it/s 0.5s\n",
            "                   all         41        261      0.998      0.986      0.995      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/150      1.88G     0.6463     0.4391     0.8129         58        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.999      0.986      0.995      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/150       1.9G     0.6467     0.4397      0.809         65        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.1it/s 0.3s\n",
            "                   all         41        261      0.993      0.994      0.995      0.829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/150      1.91G     0.6526     0.4303     0.8147         54        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         41        261      0.994       0.99      0.995      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/150      1.93G     0.6258     0.4327      0.808         61        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5it/s 0.3s\n",
            "                   all         41        261      0.995      0.989      0.995      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/150      1.95G     0.6561     0.4373     0.8148         48        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.998      0.989      0.995      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/150      1.97G     0.6141       0.44     0.8112         80        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.1it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s\n",
            "                   all         41        261          1      0.992      0.995      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/150      1.98G     0.6804     0.4541     0.8209         60        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         41        261      0.992      0.996      0.995      0.847\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 8.0ms\n",
            "Speed: 1.1ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 5.5ms\n",
            "Speed: 0.9ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 7.7ms\n",
            "Speed: 1.1ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/150      2.01G     0.6688     0.4347     0.8129         88        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         41        261      0.992      0.995      0.995      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/150      2.03G     0.6201     0.4445     0.8091         56        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         41        261      0.993      0.994      0.995      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/150      2.04G      0.649     0.4375     0.8108         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.8it/s 0.4s\n",
            "                   all         41        261      0.994      0.995      0.995      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/150      2.06G     0.6223     0.4326     0.8186         42        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.3it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.994      0.997      0.995      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/150      2.08G     0.6546     0.4222     0.8116         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.994      0.994      0.995      0.828\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/150       2.1G     0.6161     0.4342     0.8167         73        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s\n",
            "                   all         41        261      0.982          1      0.995      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/150      2.11G     0.6763     0.4404     0.8188         46        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.9it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.995      0.992      0.995      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/150      2.13G     0.6124     0.4197      0.803         71        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         41        261      0.996      0.992      0.995      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/150      2.15G     0.6482     0.4365     0.8115         59        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.4it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.8it/s 0.4s\n",
            "                   all         41        261      0.997      0.992      0.995      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    101/150      2.16G     0.6192     0.4322     0.8109         65        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         41        261      0.998      0.992      0.995      0.849\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 7.1ms\n",
            "Speed: 1.0ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.1ms\n",
            "Speed: 0.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    102/150      2.19G     0.6306     0.4289      0.814         50        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.994      0.992      0.995      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    103/150      2.21G     0.6473     0.4419     0.8133         50        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         41        261      0.995       0.99      0.995       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    104/150      2.22G     0.6308     0.4383     0.8094         71        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         41        261      0.995      0.993      0.995      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    105/150      2.24G      0.624      0.413     0.8061         54        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.6it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.4it/s 0.4s\n",
            "                   all         41        261      0.996       0.99      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    106/150      2.26G     0.6038      0.408     0.8144         66        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         41        261      0.996       0.99      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    107/150      2.28G     0.5898      0.412     0.8027         93        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.997      0.988      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    108/150      2.29G     0.6548     0.4267      0.809         78        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s\n",
            "                   all         41        261      0.998      0.988      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    109/150      2.31G     0.6223     0.4141     0.8128         64        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5it/s 0.3s\n",
            "                   all         41        261      0.998      0.989      0.995      0.862\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    110/150      2.33G     0.6146      0.422     0.8108         89        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.4it/s 0.4s\n",
            "                   all         41        261      0.993      0.996      0.995      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    111/150      2.34G     0.6128     0.4192     0.8065         65        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.9it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         41        261      0.993      0.997      0.995      0.846\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 8.3ms\n",
            "Speed: 1.2ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    112/150      2.37G     0.6258     0.4198     0.8116         68        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.993      0.997      0.995      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    113/150      2.39G     0.6172     0.4017      0.805         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         41        261      0.993      0.997      0.995      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    114/150       2.4G      0.659     0.4101     0.8132         66        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.992          1      0.995      0.863\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    115/150      2.42G     0.6187     0.4173     0.8125         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.6it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.3it/s 0.4s\n",
            "                   all         41        261      0.992          1      0.995      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    116/150      2.44G     0.5974     0.3936     0.8102         51        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.6it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         41        261          1      0.999      0.995      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    117/150      2.45G     0.6269     0.4201     0.8112         47        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.999      0.999      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    118/150      2.47G     0.6004      0.406     0.8108         63        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.999          1      0.995      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    119/150      2.49G     0.5945     0.4122     0.8071         29        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         41        261      0.998      0.999      0.995      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    120/150      2.51G     0.5826     0.3977     0.8093         74        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.7it/s 0.4s\n",
            "                   all         41        261      0.998      0.999      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    121/150      2.53G     0.5715     0.3922     0.8114         68        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.8it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         41        261      0.998      0.999      0.995      0.866\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.1ms\n",
            "Speed: 1.0ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 7.5ms\n",
            "Speed: 1.0ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    122/150      2.55G     0.6452     0.4142     0.8181         97        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         41        261      0.998      0.998      0.995      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    123/150      2.57G      0.584       0.39     0.7996         67        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         41        261      0.999      0.991      0.995      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    124/150      2.59G     0.5913      0.391     0.8111         68        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         41        261      0.991          1      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    125/150       2.6G      0.582     0.3998     0.8118         77        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.2it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 5.6it/s 0.5s\n",
            "                   all         41        261      0.992          1      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    126/150      2.62G     0.5712     0.3888     0.7993         48        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.0it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         41        261      0.992          1      0.995      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    127/150      2.64G     0.6138     0.4025     0.8158         80        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.998      0.991      0.995      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    128/150      2.65G     0.5883     0.3943     0.8033         69        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.991      0.998      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    129/150      2.67G     0.5982     0.3912     0.8075         69        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         41        261      0.999      0.991      0.995      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    130/150      2.69G     0.5843     0.3978      0.805         58        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.7it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.2it/s 0.4s\n",
            "                   all         41        261      0.997      0.992      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    131/150      2.71G     0.5753     0.3782     0.8047         88        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.8it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.9it/s 0.4s\n",
            "                   all         41        261      0.998      0.999      0.995      0.867\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 8.7ms\n",
            "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.0ms\n",
            "Speed: 1.0ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    132/150      2.75G     0.5484     0.3811     0.8133         65        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.2it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.2it/s 0.4s\n",
            "                   all         41        261      0.999      0.999      0.995      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    133/150      2.77G     0.5568     0.3821     0.8085         34        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.9it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.999      0.999      0.995      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    134/150      2.79G     0.5669     0.3741     0.8067         62        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.998      0.992      0.995      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    135/150       2.8G     0.5587     0.3686     0.8062         62        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.5it/s 0.5s\n",
            "                   all         41        261      0.997      0.992      0.995      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    136/150      2.82G     0.5635     0.3762     0.8025         71        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.4it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         41        261      0.998      0.998      0.995      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    137/150      2.84G     0.5751     0.3851     0.8118         62        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.2it/s 0.3s\n",
            "                   all         41        261      0.998      0.999      0.995      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    138/150      2.85G     0.5618     0.3675     0.8127         51        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.2it/s 0.3s\n",
            "                   all         41        261      0.998          1      0.995      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    139/150      2.87G     0.5478     0.3738     0.8057         46        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.998          1      0.995      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    140/150      2.89G     0.5711      0.377     0.8075         49        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.9it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.0it/s 0.4s\n",
            "                   all         41        261      0.998          1      0.995      0.876\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    141/150       2.9G     0.5595     0.4063     0.8075         40        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.0it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         41        261      0.998          1      0.995      0.877\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 320x288 7 otherss, 7.2ms\n",
            "Speed: 0.9ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 320x288 6 light_blues, 6.3ms\n",
            "Speed: 1.1ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 320x288 4 otherss, 6.1ms\n",
            "Speed: 1.0ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 288)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    142/150      2.93G     0.5375     0.3869     0.8061         43        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s\n",
            "                   all         41        261      0.997      0.998      0.995      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    143/150      2.95G      0.526     0.3644     0.8113         35        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.1it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         41        261      0.997      0.997      0.995      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    144/150      2.96G     0.5308     0.3782     0.8083         34        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.3it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s\n",
            "                   all         41        261      0.998      0.997      0.995      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    145/150      2.98G     0.5218     0.3727     0.8064         31        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.6it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.4it/s 0.4s\n",
            "                   all         41        261      0.998      0.997      0.995      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    146/150         3G      0.579     0.4279     0.8141         34        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.1it/s 0.3s\n",
            "                   all         41        261      0.997      0.995      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    147/150      3.02G     0.5168     0.3889     0.7983         45        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.2it/s 0.3s\n",
            "                   all         41        261      0.998      0.995      0.995      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    148/150      3.03G     0.5361     0.3725     0.7939         42        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5it/s 0.3s\n",
            "                   all         41        261      0.997      0.995      0.995      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    149/150      3.05G     0.5504     0.3833     0.8147         35        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         41        261      0.998      0.994      0.995      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    150/150      3.07G     0.5481     0.3728     0.8028         35        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 7.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 6.7it/s 0.4s\n",
            "                   all         41        261      0.994      0.998      0.995      0.866\n",
            "\n",
            "150 epochs completed in 0.112 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.232 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         41        261      0.997      0.992      0.995      0.877\n",
            "            light_blue         11         65      0.998          1      0.995       0.87\n",
            "             dark_blue         10         57      0.994      0.982      0.995      0.848\n",
            "                others         20        139          1      0.993      0.995      0.914\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "\n",
            "ðŸ“¦ Logging final artifacts...\n",
            "\n",
            "ðŸ”— Dashboard: https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/box_loss</td><td>â–‡â–†â–„â–ˆâ–ˆâ–‡â–„â–…â–…â–„â–…â–„â–„â–ƒâ–ƒâ–†â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–‚â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–</td></tr><tr><td>train/cls_loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–</td></tr><tr><td>train/dfl_loss</td><td>â–‡â–†â–…â–„â–†â–ƒâ–ˆâ–„â–ˆâ–‡â–†â–ƒâ–ƒâ–…â–…â–„â–ƒâ–‡â–„â–ƒâ–„â–…â–„â–…â–…â–…â–„â–â–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–…â–ƒ</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/total_loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/mAP50</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/mAP50-95</td><td>â–â–ƒâ–†â–„â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/precision</td><td>â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/recall</td><td>â–â–ƒâ–„â–„â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>149</td></tr><tr><td>train/box_loss</td><td>0.46271</td></tr><tr><td>train/cls_loss</td><td>0.3098</td></tr><tr><td>train/dfl_loss</td><td>0.80069</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/total_loss</td><td>0.57456</td></tr><tr><td>val/mAP50</td><td>0.99494</td></tr><tr><td>val/mAP50-95</td><td>0.87742</td></tr><tr><td>val/precision</td><td>0.99729</td></tr><tr><td>val/recall</td><td>0.99196</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">yolov8n-final2</strong> at: <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/khtuz98m</a><br> View project at: <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection</a><br>Synced 5 W&B file(s), 88 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251126_060613-khtuz98m/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸ”¥ STARTING TRAINING (ENHANCED WANDB LOGGING)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    wandb.finish()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"bottleCap-detection\",\n",
        "    name=\"yolov8n-final2\",\n",
        "    config={\n",
        "        \"epochs\": 150,\n",
        "        \"batch_size\": 8,\n",
        "        \"image_size\": 320,\n",
        "        \"architecture\": \"YOLOv8n\",\n",
        "        \"strategy\": \"High Geometry Augmentation\",\n",
        "        \"optimizer\": \"AdamW\",\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"degrees\": 90,\n",
        "        \"translate\": 0.1,\n",
        "        \"scale\": 0.6,\n",
        "        \"shear\": 10,\n",
        "        \"flipud\": 0.5,\n",
        "        \"fliplr\": 0.5,\n",
        "        \"mosaic\": 1.0,\n",
        "        \"mixup\": 0.1,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"\\nðŸ“Š Dashboard Link: {run.url}\")\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "def comprehensive_wandb_callback(trainer):\n",
        "\n",
        "    if not wandb.run:\n",
        "        return\n",
        "\n",
        "    epoch = trainer.epoch\n",
        "\n",
        "    train_losses = {\n",
        "        \"train/box_loss\": trainer.loss_items[0].item() if len(trainer.loss_items) > 0 else 0,\n",
        "        \"train/cls_loss\": trainer.loss_items[1].item() if len(trainer.loss_items) > 1 else 0,\n",
        "        \"train/dfl_loss\": trainer.loss_items[2].item() if len(trainer.loss_items) > 2 else 0,\n",
        "        \"train/total_loss\": trainer.tloss.mean().item() if trainer.tloss is not None else 0,\n",
        "    }\n",
        "\n",
        "    val_metrics = {}\n",
        "    if hasattr(trainer, \"metrics\") and trainer.metrics:\n",
        "        val_metrics = {\n",
        "            \"val/precision\": trainer.metrics.get(\"metrics/precision(B)\", 0),\n",
        "            \"val/recall\": trainer.metrics.get(\"metrics/recall(B)\", 0),\n",
        "            \"val/mAP50\": trainer.metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "            \"val/mAP50-95\": trainer.metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        }\n",
        "\n",
        "    lr_dict = {\"train/learning_rate\": trainer.optimizer.param_groups[0][\"lr\"]}\n",
        "\n",
        "    wandb.log({**train_losses, **val_metrics, **lr_dict, \"epoch\": epoch})\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        try:\n",
        "            log_predictions(trainer, epoch)\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Could not log predictions:\", e)\n",
        "\n",
        "\n",
        "def log_predictions(trainer, epoch):\n",
        "\n",
        "    val_path = Path(\"/content/yolo_dataset/val/images\")\n",
        "    val_images = list(val_path.glob(\"*.jpg\"))[:3]\n",
        "\n",
        "    try:\n",
        "        weight_path = trainer.best if hasattr(trainer, \"best\") else trainer.last\n",
        "        infer_model = YOLO(weight_path)\n",
        "    except:\n",
        "        infer_model = YOLO(trainer.model.model)\n",
        "        infer_model.eval()\n",
        "\n",
        "    prediction_images = []\n",
        "\n",
        "    for img_path in val_images:\n",
        "\n",
        "        results = infer_model(str(img_path))[0]\n",
        "\n",
        "        plotted = results.plot()\n",
        "        plotted_rgb = cv2.cvtColor(plotted, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        boxes_data = []\n",
        "        for box in results.boxes:\n",
        "            boxes_data.append({\n",
        "                \"position\": {\n",
        "                    \"minX\": float(box.xyxy[0][0]),\n",
        "                    \"minY\": float(box.xyxy[0][1]),\n",
        "                    \"maxX\": float(box.xyxy[0][2]),\n",
        "                    \"maxY\": float(box.xyxy[0][3]),\n",
        "                },\n",
        "                \"class_id\": int(box.cls[0]),\n",
        "                \"box_caption\": f\"{infer_model.names[int(box.cls[0])]} {float(box.conf[0]):.2f}\",\n",
        "                \"scores\": {\"confidence\": float(box.conf[0])},\n",
        "            })\n",
        "\n",
        "        wandb_img = wandb.Image(\n",
        "            plotted_rgb,\n",
        "            caption=f\"Epoch {epoch} - {img_path.name}\",\n",
        "            boxes={\"predictions\": {\"box_data\": boxes_data, \"class_labels\": infer_model.names}},\n",
        "        )\n",
        "\n",
        "        prediction_images.append(wandb_img)\n",
        "\n",
        "    wandb.log({f\"predictions/epoch_{epoch}\": prediction_images})\n",
        "\n",
        "\n",
        "\n",
        "model.add_callback(\"on_fit_epoch_end\", comprehensive_wandb_callback)\n",
        "\n",
        "\n",
        "print(\"\\nðŸ”¥ Starting training...\")\n",
        "results = model.train(\n",
        "    data=\"/content/yolo_dataset/data.yaml\",\n",
        "    imgsz=320,\n",
        "    epochs=150,\n",
        "    batch=8,\n",
        "    patience=0,\n",
        "    close_mosaic=10,\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    val=True,\n",
        "    save=True,\n",
        "    save_period=10,\n",
        "    verbose=True,\n",
        "    seed=42,\n",
        "    plots=True,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“¦ Logging final artifacts...\")\n",
        "\n",
        "best_model_path = Path(\"/content/runs/detect/train2/weights/best.pt\")\n",
        "if best_model_path.exists():\n",
        "    wandb.save(str(best_model_path))\n",
        "    print(\"âœ… Best model saved\")\n",
        "\n",
        "print(f\"\\nðŸ”— Dashboard: {run.url}\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syw_DB8wZgP8",
        "outputId": "9fad4b72-8661-4988-fbdc-c364be3835ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/212.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/55.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Menggunakan model: /content/runs/detect/train/weights/best.pt\n",
            "\n",
            "ðŸ”„ Sedang Export ke ONNX...\n",
            "Ultralytics 8.3.232 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train/weights/best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.75...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.8s, saved as '/content/runs/detect/train/weights/best.onnx' (11.6 MB)\n",
            "\n",
            "Export complete (0.9s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=320  \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=320 data=/content/yolo_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“‰ Sedang Melakukan Kuantisasi (Int8)...\n",
            "ðŸŽ‰ Selesai! Model tersimpan di:\n",
            "   Original  : /content/runs/detect/train/weights/best.onnx (11.58 MB)\n",
            "   Quantized : /content/runs/detect/train/weights/best_int8.onnx (3.08 MB)\n",
            "\n",
            "==================================================\n",
            "ðŸ“ SIMULASI PERFORMA RASPBERRY PI 5\n",
            "==================================================\n",
            "ðŸ”¥ Warming up engine...\n",
            "ðŸƒ Running benchmark (100 iterasi)...\n",
            "\n",
            "ðŸ“Š HASIL PENGUJIAN (Estimasi):\n",
            "   Model       : YOLOv8 (Int8 Quantized)\n",
            "   Image Size  : 320x320\n",
            "   Rata-rata Latency : 107.80 ms\n",
            "   95% Latency       : 183.01 ms\n",
            "   Estimasi FPS      : 9.28 FPS\n",
            "\n",
            "â„¹ï¸ Catatan:\n",
            "   - Angka ini adalah simulasi 'Upper Bound' (batas atas).\n",
            "   - Di Raspberry Pi 5 asli, performa mungkin sedikit berbeda tergantung thermal throttling.\n",
            "   - Namun, model Int8 ini jauh lebih ringan daripada model PyTorch asli.\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime as ort\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "possible_paths = list(Path('/content/runs/detect').glob('*/weights/best.pt'))\n",
        "if not possible_paths:\n",
        "    raise FileNotFoundError(\"âŒ Model best.pt tidak ditemukan! Pastikan training sudah selesai.\")\n",
        "\n",
        "best_model_path = max(possible_paths, key=os.path.getmtime)\n",
        "print(f\"âœ… Menggunakan model: {best_model_path}\")\n",
        "\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "print(\"\\nðŸ”„ Sedang Export ke ONNX...\")\n",
        "model.export(format='onnx', imgsz=320, dynamic=False, simplify=True)\n",
        "\n",
        "onnx_path = str(best_model_path).replace('.pt', '.onnx')\n",
        "quantized_path = str(best_model_path).replace('.pt', '_int8.onnx')\n",
        "\n",
        "print(\"\\nðŸ“‰ Sedang Melakukan Kuantisasi (Int8)...\")\n",
        "quantize_dynamic(\n",
        "    model_input=onnx_path,\n",
        "    model_output=quantized_path,\n",
        "    weight_type=QuantType.QUInt8\n",
        ")\n",
        "\n",
        "print(f\"ðŸŽ‰ Selesai! Model tersimpan di:\")\n",
        "print(f\"   Original  : {onnx_path} ({os.path.getsize(onnx_path)/1024/1024:.2f} MB)\")\n",
        "print(f\"   Quantized : {quantized_path} ({os.path.getsize(quantized_path)/1024/1024:.2f} MB)\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ðŸ“ SIMULASI PERFORMA RASPBERRY PI 5\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "sess_options = ort.SessionOptions()\n",
        "sess_options.intra_op_num_threads = 4\n",
        "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "session = ort.InferenceSession(quantized_path, sess_options, providers=['CPUExecutionProvider'])\n",
        "\n",
        "input_name = session.get_inputs()[0].name\n",
        "dummy_input = np.random.randn(1, 3, 320, 320).astype(np.float32)\n",
        "\n",
        "print(\"ðŸ”¥ Warming up engine...\")\n",
        "for _ in range(10):\n",
        "    session.run(None, {input_name: dummy_input})\n",
        "\n",
        "num_runs = 100\n",
        "latencies = []\n",
        "\n",
        "print(f\"ðŸƒ Running benchmark ({num_runs} iterasi)...\")\n",
        "for i in range(num_runs):\n",
        "    start_time = time.time()\n",
        "    session.run(None, {input_name: dummy_input})\n",
        "    end_time = time.time()\n",
        "    latencies.append((end_time - start_time) * 1000)\n",
        "\n",
        "avg_latency = np.mean(latencies)\n",
        "fps = 1000 / avg_latency\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "\n",
        "print(\"\\nðŸ“Š HASIL PENGUJIAN (Estimasi):\")\n",
        "print(f\"   Model       : YOLOv8 (Int8 Quantized)\")\n",
        "print(f\"   Image Size  : 320x320\")\n",
        "print(f\"   Rata-rata Latency : {avg_latency:.2f} ms\")\n",
        "print(f\"   95% Latency       : {p95_latency:.2f} ms\")\n",
        "print(f\"   Estimasi FPS      : {fps:.2f} FPS\")\n",
        "\n",
        "print(\"\\nâ„¹ï¸ Catatan:\")\n",
        "print(\"   - Angka ini adalah simulasi 'Upper Bound' (batas atas).\")\n",
        "print(\"   - Di Raspberry Pi 5 asli, performa mungkin sedikit berbeda tergantung thermal throttling.\")\n",
        "print(\"   - Namun, model Int8 ini jauh lebih ringan daripada model PyTorch asli.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸ”¥ STARTING TRAINING (ENHANCED WANDB LOGGING)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    wandb.finish()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"bottleCap-detection\",\n",
        "    name=\"yolov8n-128\",\n",
        "    config={\n",
        "        \"epochs\": 150,\n",
        "        \"batch_size\": 16,\n",
        "        \"image_size\": 128,\n",
        "        \"architecture\": \"YOLOv8n\",\n",
        "        \"strategy\": \"High Geometry Augmentation\",\n",
        "        \"optimizer\": \"AdamW\",\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"degrees\": 90,\n",
        "        \"translate\": 0.1,\n",
        "        \"scale\": 0.6,\n",
        "        \"shear\": 10,\n",
        "        \"flipud\": 0.5,\n",
        "        \"fliplr\": 0.5,\n",
        "        \"mosaic\": 1.0,\n",
        "        \"mixup\": 0.1,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"\\nðŸ“Š Dashboard Link: {run.url}\")\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "\n",
        "def comprehensive_wandb_callback(trainer):\n",
        "\n",
        "    if not wandb.run:\n",
        "        return\n",
        "\n",
        "    epoch = trainer.epoch\n",
        "\n",
        "    train_losses = {\n",
        "        \"train/box_loss\": trainer.loss_items[0].item() if len(trainer.loss_items) > 0 else 0,\n",
        "        \"train/cls_loss\": trainer.loss_items[1].item() if len(trainer.loss_items) > 1 else 0,\n",
        "        \"train/dfl_loss\": trainer.loss_items[2].item() if len(trainer.loss_items) > 2 else 0,\n",
        "        \"train/total_loss\": trainer.tloss.mean().item() if trainer.tloss is not None else 0,\n",
        "    }\n",
        "\n",
        "    val_metrics = {}\n",
        "    if hasattr(trainer, \"metrics\") and trainer.metrics:\n",
        "        val_metrics = {\n",
        "            \"val/precision\": trainer.metrics.get(\"metrics/precision(B)\", 0),\n",
        "            \"val/recall\": trainer.metrics.get(\"metrics/recall(B)\", 0),\n",
        "            \"val/mAP50\": trainer.metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "            \"val/mAP50-95\": trainer.metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        }\n",
        "\n",
        "    lr_dict = {\"train/learning_rate\": trainer.optimizer.param_groups[0][\"lr\"]}\n",
        "\n",
        "    wandb.log({**train_losses, **val_metrics, **lr_dict, \"epoch\": epoch})\n",
        "\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        try:\n",
        "            log_predictions(trainer, epoch)\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Could not log predictions:\", e)\n",
        "\n",
        "\n",
        "def log_predictions(trainer, epoch):\n",
        "\n",
        "    val_path = Path(\"/content/yolo_dataset/val/images\")\n",
        "    val_images = list(val_path.glob(\"*.jpg\"))[:3]\n",
        "\n",
        "\n",
        "    try:\n",
        "        weight_path = trainer.best if hasattr(trainer, \"best\") else trainer.last\n",
        "        infer_model = YOLO(weight_path)\n",
        "    except:\n",
        "        infer_model = YOLO(trainer.model.model)\n",
        "        infer_model.eval()\n",
        "\n",
        "    prediction_images = []\n",
        "\n",
        "    for img_path in val_images:\n",
        "\n",
        "        results = infer_model(str(img_path))[0]\n",
        "\n",
        "        plotted = results.plot()\n",
        "        plotted_rgb = cv2.cvtColor(plotted, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        boxes_data = []\n",
        "        for box in results.boxes:\n",
        "            boxes_data.append({\n",
        "                \"position\": {\n",
        "                    \"minX\": float(box.xyxy[0][0]),\n",
        "                    \"minY\": float(box.xyxy[0][1]),\n",
        "                    \"maxX\": float(box.xyxy[0][2]),\n",
        "                    \"maxY\": float(box.xyxy[0][3]),\n",
        "                },\n",
        "                \"class_id\": int(box.cls[0]),\n",
        "                \"box_caption\": f\"{infer_model.names[int(box.cls[0])]} {float(box.conf[0]):.2f}\",\n",
        "                \"scores\": {\"confidence\": float(box.conf[0])},\n",
        "            })\n",
        "\n",
        "        wandb_img = wandb.Image(\n",
        "            plotted_rgb,\n",
        "            caption=f\"Epoch {epoch} - {img_path.name}\",\n",
        "            boxes={\"predictions\": {\"box_data\": boxes_data, \"class_labels\": infer_model.names}},\n",
        "        )\n",
        "\n",
        "        prediction_images.append(wandb_img)\n",
        "\n",
        "    wandb.log({f\"predictions/epoch_{epoch}\": prediction_images})\n",
        "\n",
        "\n",
        "\n",
        "model.add_callback(\"on_fit_epoch_end\", comprehensive_wandb_callback)\n",
        "\n",
        "\n",
        "print(\"\\nðŸ”¥ Starting training...\")\n",
        "results = model.train(\n",
        "    data=\"/content/yolo_dataset/data.yaml\",\n",
        "    imgsz=128,\n",
        "    epochs=150,\n",
        "    batch=16,\n",
        "    patience=10,\n",
        "    freeze=0,\n",
        "    close_mosaic=10,\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    val=True,\n",
        "    save=True,\n",
        "    save_period=10,\n",
        "    verbose=True,\n",
        "    seed=42,\n",
        "    plots=True,\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ“¦ Logging final artifacts...\")\n",
        "\n",
        "best_model_path = Path(\"/content/runs/detect/train2/weights/best.pt\")\n",
        "if best_model_path.exists():\n",
        "    wandb.save(str(best_model_path))\n",
        "    print(\"âœ… Best model saved\")\n",
        "\n",
        "print(f\"\\nðŸ”— Dashboard: {run.url}\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1dknV7gK1ofq",
        "outputId": "e37acfd6-b380-43dd-ec2a-2623eff883d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ðŸ”¥ STARTING TRAINING (ENHANCED WANDB LOGGING)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">yolov8n-128</strong> at: <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/iy3dqudb' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/iy3dqudb</a><br> View project at: <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251126_062829-iy3dqudb/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251126_062844-vurlkwu3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3' target=\"_blank\">yolov8n-128</a></strong> to <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Dashboard Link: https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3\n",
            "\n",
            "ðŸ”¥ Starting training...\n",
            "Ultralytics 8.3.232 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=0, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=128, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train2, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1244.6Â±596.2 MB/s, size: 65.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/train/labels.cache... 142 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 142/142 146.2Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 466.1Â±158.2 MB/s, size: 242.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/val/labels.cache... 41 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 42.1Kit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 128 train, 128 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/150     0.641G      2.485      4.135      1.014        166        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 4.3it/s 0.5s\n",
            "                   all         41        261          0          0          0          0\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 (no detections), 5.7ms\n",
            "Speed: 0.7ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 (no detections), 8.7ms\n",
            "Speed: 0.7ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 (no detections), 6.1ms\n",
            "Speed: 0.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/150     0.641G      2.061      3.142     0.8967        113        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.7it/s 1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261    0.00173      0.153     0.0442     0.0113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/150     0.641G      2.002      2.299      0.878        161        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.9it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.7it/s 0.3s\n",
            "                   all         41        261     0.0263      0.226      0.106     0.0257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/150     0.641G      1.887      1.918     0.8523        119        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.6it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 9.1it/s 0.2s\n",
            "                   all         41        261      0.784      0.149      0.129     0.0297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/150     0.641G      1.852      1.742     0.8569        115        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.9it/s 0.2s\n",
            "                   all         41        261      0.458      0.212      0.389      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/150     0.641G      1.797      1.587     0.8457        180        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.2it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.5it/s 0.3s\n",
            "                   all         41        261      0.497      0.508      0.468      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/150     0.641G       1.74      1.528     0.8436        160        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.0it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.8it/s 0.5s\n",
            "                   all         41        261      0.575      0.646      0.569      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/150     0.641G      1.747       1.39     0.8384        137        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.5it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 5.0it/s 0.4s\n",
            "                   all         41        261      0.702      0.614      0.674      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/150     0.641G      1.667      1.271     0.8327        149        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.5it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.5it/s 0.3s\n",
            "                   all         41        261      0.603      0.641      0.703      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/150     0.641G      1.682      1.297     0.8329        146        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.0it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.587      0.741       0.71      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/150     0.641G      1.773      1.293     0.8406        176        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.2it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.6it/s 0.2s\n",
            "                   all         41        261      0.619      0.802      0.712      0.395\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 (no detections), 5.5ms\n",
            "Speed: 0.5ms preprocess, 5.5ms inference, 0.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 (no detections), 6.1ms\n",
            "Speed: 0.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 (no detections), 7.6ms\n",
            "Speed: 0.6ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/150     0.641G      1.664      1.147     0.8235        171        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.5it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.659       0.79      0.705      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/150     0.641G      1.676      1.168     0.8202        153        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.9it/s 0.3s\n",
            "                   all         41        261      0.669      0.802      0.744      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/150     0.641G       1.77      1.164      0.827        167        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.1it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.7it/s 0.3s\n",
            "                   all         41        261       0.68      0.873      0.814      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/150     0.641G      1.656      1.123     0.8325        108        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.5it/s 0.3s\n",
            "                   all         41        261      0.723       0.85      0.827      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/150     0.641G      1.627      1.118     0.8181        135        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.2it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.2it/s 0.3s\n",
            "                   all         41        261       0.71      0.822      0.819      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/150     0.641G      1.624      1.062     0.8155        119        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.7it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.4it/s 0.2s\n",
            "                   all         41        261      0.755      0.812      0.825      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/150     0.641G      1.677      1.088     0.8164        130        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s\n",
            "                   all         41        261      0.759      0.841      0.852      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/150     0.641G      1.665      1.052     0.8315        138        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.7it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.5it/s 0.2s\n",
            "                   all         41        261      0.807      0.862      0.876      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/150     0.641G      1.666      1.026     0.8293        140        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.6it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.3it/s 0.3s\n",
            "                   all         41        261      0.858      0.861      0.905      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/150     0.641G       1.53     0.9643     0.8211        151        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.8it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.0it/s 0.3s\n",
            "                   all         41        261      0.879      0.841      0.883      0.553\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 9 otherss, 8.6ms\n",
            "Speed: 0.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 5 light_blues, 6.3ms\n",
            "Speed: 0.6ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 6.1ms\n",
            "Speed: 0.6ms preprocess, 6.1ms inference, 1.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/150     0.641G      1.489     0.9625     0.8163        145        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.0it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.5it/s 0.3s\n",
            "                   all         41        261      0.914      0.833      0.897      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/150     0.641G      1.519     0.9322     0.8133        137        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.9it/s 1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 5.5it/s 0.4s\n",
            "                   all         41        261      0.901      0.893      0.947      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/150     0.641G      1.479     0.9292      0.823        132        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 5.0it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.2it/s 0.3s\n",
            "                   all         41        261      0.894      0.921      0.965      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/150     0.641G      1.425     0.8712     0.8115        167        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.1it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.2it/s 0.3s\n",
            "                   all         41        261      0.907       0.93      0.968       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/150     0.641G      1.456     0.9422     0.8241        121        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.8it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.5it/s 0.3s\n",
            "                   all         41        261      0.959       0.92      0.957      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/150     0.641G      1.458     0.8634     0.8246        142        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.6it/s 0.3s\n",
            "                   all         41        261      0.939      0.951      0.973      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/150     0.641G      1.403     0.8171     0.8022        141        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.6it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.4it/s 0.2s\n",
            "                   all         41        261      0.965       0.95      0.973      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/150     0.641G      1.432     0.8438     0.8178        141        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.0it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.1it/s 0.3s\n",
            "                   all         41        261      0.961      0.961      0.975      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/150     0.641G      1.525     0.8555     0.8199        181        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.8it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.8it/s 0.2s\n",
            "                   all         41        261      0.947      0.926      0.975      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/150     0.641G      1.523     0.8836     0.8217        132        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.8it/s 1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 4.1it/s 0.5s\n",
            "                   all         41        261      0.889      0.887      0.969      0.583\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 9 otherss, 6.5ms\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 6 light_blues, 7.6ms\n",
            "Speed: 0.7ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 8.7ms\n",
            "Speed: 0.8ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/150     0.641G      1.492     0.8514     0.8157        159        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.4it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.7it/s 0.3s\n",
            "                   all         41        261      0.886       0.83      0.955      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/150     0.641G      1.521     0.8677     0.8131        130        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.6it/s 0.3s\n",
            "                   all         41        261      0.931      0.834      0.958      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/150     0.641G      1.522     0.8578     0.8249        119        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.8it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.9it/s 0.2s\n",
            "                   all         41        261      0.952      0.853      0.959      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/150     0.641G      1.447     0.8014     0.8111        127        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.2it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.8it/s 0.2s\n",
            "                   all         41        261      0.947      0.891      0.968      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/150     0.641G      1.412     0.8499     0.8177        159        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.2it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261       0.94      0.913      0.971      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/150     0.641G      1.463     0.8348     0.8166        216        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.3it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.964      0.936      0.973      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/150     0.641G      1.436     0.8079     0.8194        132        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.2it/s 0.3s\n",
            "                   all         41        261      0.983       0.95      0.977       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/150     0.641G       1.43     0.8099     0.8106        118        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.6it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 5.3it/s 0.4s\n",
            "                   all         41        261      0.976      0.954      0.977      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/150     0.641G      1.368     0.8087     0.8169        137        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.6it/s 0.2s\n",
            "                   all         41        261      0.972      0.961      0.978      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/150     0.641G      1.442     0.7743     0.8098        176        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.8it/s 0.2s\n",
            "                   all         41        261      0.965      0.958      0.978      0.677\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 9 otherss, 8.9ms\n",
            "Speed: 0.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 6 light_blues, 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 6.3ms\n",
            "Speed: 0.6ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/150     0.641G      1.323     0.7455     0.8066        158        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.6it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.3it/s 0.3s\n",
            "                   all         41        261      0.955      0.941      0.977      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/150     0.641G      1.356     0.7716     0.8065        110        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.3it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.3it/s 0.3s\n",
            "                   all         41        261      0.974      0.925      0.976      0.656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/150     0.641G      1.344      0.743     0.8181        167        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.0it/s 0.3s\n",
            "                   all         41        261      0.939      0.925      0.969      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/150     0.641G      1.262     0.7082     0.8072        131        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.6it/s 0.2s\n",
            "                   all         41        261       0.96      0.917      0.967      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/150     0.641G      1.393      0.789     0.8173        162        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.9it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.9it/s 0.3s\n",
            "                   all         41        261      0.971      0.925      0.974      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/150     0.641G      1.321     0.7336     0.8216        145        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.5it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 4.1it/s 0.5s\n",
            "                   all         41        261      0.977      0.927      0.974      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/150     0.641G       1.34     0.7768     0.8129        135        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.2it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 5.7it/s 0.4s\n",
            "                   all         41        261      0.983      0.909      0.975      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/150     0.641G      1.297     0.7131     0.8177        140        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.7it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.0it/s 0.3s\n",
            "                   all         41        261      0.968        0.9      0.973      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/150     0.641G      1.356     0.7549     0.8212        126        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.1it/s 0.2s\n",
            "                   all         41        261      0.984      0.891      0.974      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/150     0.641G      1.325     0.7471     0.8079        163        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.8it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.961      0.916      0.978      0.706\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 9 otherss, 5.7ms\n",
            "Speed: 0.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 6 light_blues, 1 dark_blue, 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/150     0.641G      1.356     0.7255     0.8181        128        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.5it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.0it/s 0.3s\n",
            "                   all         41        261      0.968      0.919      0.978       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/150     0.641G      1.311     0.7528     0.8104        126        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.5it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.9it/s 0.3s\n",
            "                   all         41        261      0.985      0.918      0.979      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/150     0.641G      1.349     0.7303     0.8138        142        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.7it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.6it/s 0.2s\n",
            "                   all         41        261      0.969      0.935      0.975      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/150     0.641G      1.309     0.7401     0.8091        145        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1it/s 1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.1it/s 0.3s\n",
            "                   all         41        261      0.983      0.925      0.976      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/150     0.641G      1.287      0.688     0.8161        126        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.2it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 4.9it/s 0.4s\n",
            "                   all         41        261      0.971      0.952      0.979      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/150     0.641G      1.281     0.6937     0.7982        125        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.6it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.976      0.939      0.977      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/150     0.641G      1.234     0.6812     0.7936        155        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.0it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.9it/s 0.2s\n",
            "                   all         41        261      0.962      0.933      0.969      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/150     0.641G       1.21     0.6826     0.8066        146        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.0it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.1it/s 0.2s\n",
            "                   all         41        261       0.95       0.93      0.964      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/150     0.641G      1.275     0.6819     0.8069        179        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.7it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.959      0.946       0.97      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/150     0.641G      1.192     0.6561     0.8118        112        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.0it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.4it/s 0.3s\n",
            "                   all         41        261      0.989      0.936      0.978      0.714\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 8 otherss, 7.6ms\n",
            "Speed: 0.5ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 6 light_blues, 6.3ms\n",
            "Speed: 0.6ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 6.0ms\n",
            "Speed: 0.5ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/150     0.641G      1.238     0.7082     0.8074        131        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.9it/s 0.3s\n",
            "                   all         41        261      0.973      0.958      0.979      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/150     0.641G      1.273     0.7012     0.8056        164        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.2it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 6.7it/s 0.3s\n",
            "                   all         41        261      0.994      0.943       0.98      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/150     0.641G      1.283     0.7063     0.8077        129        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 6.5it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 4.5it/s 0.4s\n",
            "                   all         41        261      0.976      0.927      0.982      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/150     0.641G      1.274     0.6882     0.8028        128        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.8it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.3it/s 0.3s\n",
            "                   all         41        261      0.943      0.934      0.981      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/150     0.641G      1.278     0.7231     0.8074        145        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.4it/s 0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.0it/s 0.2s\n",
            "                   all         41        261      0.983      0.916      0.981      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/150     0.641G      1.301     0.6929     0.8131        153        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 7.6it/s 0.3s\n",
            "                   all         41        261      0.989      0.928       0.98      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/150     0.641G      1.226     0.6443     0.7995        160        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.4it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 8.5it/s 0.2s\n",
            "                   all         41        261      0.973      0.949       0.98      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/150     0.641G      1.258      0.667     0.8149        135        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 10.5it/s 0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 5.9it/s 0.3s\n",
            "                   all         41        261      0.981       0.95      0.981      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/150     0.641G        1.3     0.6918     0.8047        156        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 6.9it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 5.5it/s 0.4s\n",
            "                   all         41        261      0.985      0.948      0.981      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/150     0.641G      1.237     0.6951     0.8091        163        128: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.7it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 4.4it/s 0.5s\n",
            "                   all         41        261      0.988      0.942      0.982      0.684\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 61, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 8 otherss, 7.1ms\n",
            "Speed: 0.6ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 6 light_blues, 7.4ms\n",
            "Speed: 0.7ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 7.6ms\n",
            "Speed: 0.7ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "71 epochs completed in 0.034 hours.\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.232 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.6it/s 0.8s\n",
            "                   all         41        261      0.989      0.936      0.978      0.714\n",
            "            light_blue         11         65      0.983      0.875      0.967      0.662\n",
            "             dark_blue         10         57          1      0.982      0.994      0.764\n",
            "                others         20        139      0.985      0.951      0.974      0.714\n",
            "Speed: 0.4ms preprocess, 3.3ms inference, 0.1ms loss, 8.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_13_raw-250110_dc_s001_b2_15.jpg: 128x128 8 otherss, 5.5ms\n",
            "Speed: 0.5ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_3_raw-250110_dc_s001_b4_2.jpg: 128x128 6 light_blues, 8.3ms\n",
            "Speed: 0.7ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 128)\n",
            "\n",
            "image 1/1 /content/yolo_dataset/val/images/aug_6_raw-250110_dc_s001_b2_1.jpg: 128x128 1 others, 7.1ms\n",
            "Speed: 0.6ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 128, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“¦ Logging final artifacts...\n",
            "âœ… Best model saved\n",
            "\n",
            "ðŸ”— Dashboard: https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/box_loss</td><td>â–†â–ˆâ–†â–„â–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–ƒâ–„â–„â–ƒâ–…â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–â–ƒ</td></tr><tr><td>train/cls_loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/dfl_loss</td><td>â–ˆâ–…â–†â–…â–„â–ƒâ–…â–‚â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–ƒâ–„â–„â–‚â–â–„â–„â–ƒâ–„â–„â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–„</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/total_loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/mAP50</td><td>â–â–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/mAP50-95</td><td>â–â–â–â–â–‚â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/precision</td><td>â–â–â–â–„â–…â–†â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/recall</td><td>â–â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train/box_loss</td><td>1.44339</td></tr><tr><td>train/cls_loss</td><td>0.77721</td></tr><tr><td>train/dfl_loss</td><td>0.84029</td></tr><tr><td>train/learning_rate</td><td>0.00054</td></tr><tr><td>train/total_loss</td><td>0.91376</td></tr><tr><td>val/mAP50</td><td>0.97832</td></tr><tr><td>val/mAP50-95</td><td>0.71357</td></tr><tr><td>val/precision</td><td>0.98927</td></tr><tr><td>val/recall</td><td>0.93562</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">yolov8n-128</strong> at: <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection/runs/vurlkwu3</a><br> View project at: <a href='https://wandb.ai/andreanagari-unemployed/bottleCap-detection' target=\"_blank\">https://wandb.ai/andreanagari-unemployed/bottleCap-detection</a><br>Synced 5 W&B file(s), 50 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251126_062844-vurlkwu3/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bpjrmhjEqxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8713b7-3b7f-4ab8-c02a-3c2b8c72d4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Menggunakan model: /content/runs/detect/train2/weights/best.pt\n",
            "\n",
            "ðŸ“¦ Exporting ke ONNX (128x128)...\n",
            "Ultralytics 8.3.232 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train2/weights/best.pt' with input shape (1, 3, 128, 128) BCHW and output shape(s) (1, 7, 336) (5.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.75...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.4s, saved as '/content/runs/detect/train2/weights/best.onnx' (11.5 MB)\n",
            "\n",
            "Export complete (1.7s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train2/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/train2/weights/best.onnx imgsz=128  \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/train2/weights/best.onnx imgsz=128 data=/content/yolo_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“‰ Melakukan Kuantisasi Int8...\n",
            "âœ… Kompresi Selesai!\n",
            "   Original  : 11.54 MB\n",
            "   Quantized : 3.04 MB (Lebih kecil 3.8x)\n",
            "\n",
            "==================================================\n",
            "âš¡ BENCHMARK SPEED TEST (Simulasi RPi 5)\n",
            "==================================================\n",
            "ðŸ”¥ Warming up...\n",
            "ðŸƒ Running 200 inferences...\n",
            "\n",
            "ðŸ“Š HASIL AKHIR (128x128 Int8):\n",
            "   Rata-rata Latency : 28.73 ms\n",
            "   95% Latency       : 50.85 ms\n",
            "   Estimasi FPS      : 34.81 FPS\n",
            "\n",
            "ðŸ’¡ Kesimpulan:\n",
            "âš ï¸ Masih agak berat. Pastikan nanti di RPi menggunakan implementasi C++ (NCNN) bukan Python.\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime as ort\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model_path = Path(\"/content/runs/detect/train2/weights/best.pt\")\n",
        "\n",
        "if not model_path.exists():\n",
        "    print(f\"âš ï¸ Model tidak ditemukan di: {model_path}\")\n",
        "    print(\"   Mencari alternatif di folder runs...\")\n",
        "    possible_paths = list(Path('/content/runs/detect').glob('*/weights/best.pt'))\n",
        "    if possible_paths:\n",
        "        model_path = max(possible_paths, key=os.path.getmtime)\n",
        "        print(f\"âœ… Ditemukan model alternatif: {model_path}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"âŒ Tidak ada model best.pt ditemukan! Pastikan training 128x128 sudah selesai.\")\n",
        "else:\n",
        "    print(f\"âœ… Menggunakan model: {model_path}\")\n",
        "\n",
        "model = YOLO(model_path)\n",
        "target_size = 128\n",
        "\n",
        "print(f\"\\nðŸ“¦ Exporting ke ONNX ({target_size}x{target_size})...\")\n",
        "onnx_path = f\"/content/yolo_tiny_{target_size}.onnx\"\n",
        "\n",
        "model.export(\n",
        "    format='onnx',\n",
        "    imgsz=target_size,\n",
        "    dynamic=False,\n",
        "    simplify=True\n",
        ")\n",
        "\n",
        "exported_onnx = model_path.with_suffix('.onnx')\n",
        "if exported_onnx.exists():\n",
        "    os.rename(exported_onnx, onnx_path)\n",
        "\n",
        "print(\"\\nðŸ“‰ Melakukan Kuantisasi Int8...\")\n",
        "quantized_path = f\"/content/yolo_tiny_{target_size}_int8.onnx\"\n",
        "\n",
        "quantize_dynamic(\n",
        "    model_input=onnx_path,\n",
        "    model_output=quantized_path,\n",
        "    weight_type=QuantType.QUInt8\n",
        ")\n",
        "\n",
        "original_size = os.path.getsize(onnx_path) / (1024*1024)\n",
        "quantized_size = os.path.getsize(quantized_path) / (1024*1024)\n",
        "\n",
        "print(f\"âœ… Kompresi Selesai!\")\n",
        "print(f\"   Original  : {original_size:.2f} MB\")\n",
        "print(f\"   Quantized : {quantized_size:.2f} MB (Lebih kecil {original_size/quantized_size:.1f}x)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"âš¡ BENCHMARK SPEED TEST (Simulasi RPi 5)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "sess_options = ort.SessionOptions()\n",
        "sess_options.intra_op_num_threads = 4\n",
        "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "session = ort.InferenceSession(quantized_path, sess_options, providers=['CPUExecutionProvider'])\n",
        "input_name = session.get_inputs()[0].name\n",
        "\n",
        "dummy_input = np.random.randn(1, 3, target_size, target_size).astype(np.float32)\n",
        "\n",
        "print(\"ðŸ”¥ Warming up...\")\n",
        "for _ in range(20):\n",
        "    session.run(None, {input_name: dummy_input})\n",
        "\n",
        "num_runs = 200\n",
        "print(f\"ðŸƒ Running {num_runs} inferences...\")\n",
        "latencies = []\n",
        "\n",
        "for i in range(num_runs):\n",
        "    start = time.time()\n",
        "    session.run(None, {input_name: dummy_input})\n",
        "    end = time.time()\n",
        "    latencies.append((end - start) * 1000)\n",
        "\n",
        "avg_latency = np.mean(latencies)\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "fps = 1000 / avg_latency\n",
        "\n",
        "print(f\"\\nðŸ“Š HASIL AKHIR ({target_size}x{target_size} Int8):\")\n",
        "print(f\"   Rata-rata Latency : {avg_latency:.2f} ms\")\n",
        "print(f\"   95% Latency       : {p95_latency:.2f} ms\")\n",
        "print(f\"   Estimasi FPS      : {fps:.2f} FPS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}